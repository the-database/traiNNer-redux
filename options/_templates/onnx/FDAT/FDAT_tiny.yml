# yaml-language-server: $schema=https://raw.githubusercontent.com/the-database/traiNNer-redux/refs/heads/master/schemas/redux-config.schema.json
####################
# General Settings
####################
name: 4x_FDAT_tiny
scale: 4  # 1, 2, 3, 4, 8
num_gpu: auto

#####################
# Network Settings
#####################
# Generator model settings
network_g:
  type: fdat_tiny

############################
# Pretrain and Resume Paths
############################
path:
  # Path of the model to convert to ONNX.
  pretrain_network_g: experiments/4x_FDAT_tiny/models/net_g_ema_1000.safetensors

#########################
# ONNX conversion options
#########################
onnx:
  dynamo: false  # Whether to use the new ONNX exporter. Currently not supported on many architectures.
  fp16: false  # Whether to also export to reduced fp16 precision. Not recommend if using with TensorRT.
  opset: 20  # ONNX opset version, higher is newer. Supports up to 20 with dynamo: false and up to 23 with dynamo: true. With TensorRT higher opset is not necessarily faster.
  shape: 1x3xHxW  # Input shape in NxCxHxW. Use numbers for fixed dimensions and letters for dynamic ones (e.g. 1x3xHxW = batch=1, channels=3, dynamic height/width; 1x3x256x256 = fully static).
  verify: true  # Verify the accuracy of the ONNX model after exporting it.
  optimize: false  # Runs OnnxSlim on the model to potentially slim the model and improve inference speed. Can cause issues with TensorRT.
